#Comment#
#NON_LINEARITY = NL_SIGMOID , NL_TANH , NL_RELU#
IS_GRADIENT_CHECKING = false;   #is true when debug#
BOOST_METHOD = true;            #allow boost weight train#
EFFECT_RATIO = true;            #use e^k_{i|j}/o^{k-1}_j for estimate the grad of syn effect#
                                #need to set batch = 1 in this case#

OPTIMIZER = adam;                # use adam as the optimizer , by default is sgd with momentum #
DYNAMIC_THRESHOLD = false;       # allow dynamic threshold#
SHOWIMAGE = false;              #show the images after transformation#
TEST_EPOCH = 100;                 #the period to get the test dataset's error rate#

WHITE_NOISE = 0.0;  
LAMBDA_REG  = 10;               # param for weight regularization #
BETA_REG    = 0.01;               

WEIGHT_LIMIT= 8.0;

BATCH_SIZE = 1;
CHANNELS = 1;                   #1, 3, 4#
END_TIME = 600;                 #The spike train duration#


TRAIN_PER_CLASS = -1;               # number of train/test samples per class #
TEST_PER_CLASS = -1;
TRAIN_DATA_PATH = ./N-MNIST/train;  # train and test path for the speech samples #
TEST_DATA_PATH =  ./N-MNIST/test;    

[
LAYER = DATASPIKING;
NAME  = data;
NUM_NEURONS = 2312;
]

[
LAYER = SPIKING;
NAME  = hidden_0;
NUM_NEURONS = 500;
INPUT = data;
VTH = 15;
T_REFRAC = 2;
TAU_M = 64;
TAU_S = 8;
initW = 1;
initType = Bernoulli;
selfLoopStrength = 0;
selfLoopRatio = 1;
LearningRate = 0.001;
]

[
LAYER = RESERVOIR;
NAME  = reservoir;
NUM_NEURONS = 500;
INPUT = hidden_0;
VTH = 15;
T_REFRAC = 2;
TAU_M = 64;
TAU_S = 8;
initW = 1;
Train_Reservoir = true;
#weightConnect = 32;#     # number of neurons connects to each input neuron #
initType = Bernoulli;
laterialType = RESERVOIR;  # the laterical connections type: RESERVOIR or LOCAL_INHIBITION # 
reservoirDim = 10 x 10 x 5;
LearningRate = 0.001;
]

[
LAYER = SPIKING;
NUM_CLASSES = 10;
NAME  = output;
NUM_NEURONS = 10;
INPUT = reservoir;
VTH = 8;
T_REFRAC = 2;
TAU_M = 64;
TAU_S = 8;
initW = 1;
initType = Bernoulli;
laterialType = LOCAL_INHIBITION;
localInbStrength = 1;
DESIRED_LEVEL = 35;
UNDESIRED_LEVEL = 5;
MARGIN = 5;
LearningRate = 0.001;
]

