#Comment#
#NON_LINEARITY = NL_SIGMOID , NL_TANH , NL_RELU#
IS_GRADIENT_CHECKING = false;   #is true when debug#
SHOWIMAGE = false;              #show the images after transformation#
TEST_EPOCH = 400;                 #the period to get the test dataset's error rate#
WHITE_NOISE = 0.0;  
OPTIMIZER = adam;                # use adam as the optimizer , by default is sgd with momentum #
DYNAMIC_THRESHOLD = false;       
BOOST_METHOD = true;            #allow boost weight train#
EFFECT_RATIO = true;            #use e^k_{i|j}/o^{k-1}_j for estimate the grad of syn effect#

BATCH_SIZE = 1;                
CHANNELS = 1;                   #1, 3, 4#
END_TIME =  700;                 #The spike train duration#

TRAIN_SAMPLES = 2475;              # number of train/test samples#
TEST_SAMPLES = 2474;
TRAIN_DATA_PATH = ./n_tidigits_ab/Train/;  # train and test path for the speech samples #
TEST_DATA_PATH = ./n_tidigits_ab/Test/;    

[
LAYER = DATASPIKING;
NAME  = data;
NUM_NEURONS = 64;
]

[
LAYER = SPIKING;
NAME  = hidden_1;
NUM_NEURONS = 250;
INPUT = data;
VTH = 10;
T_REFRAC = 2;
TAU_M = 128;
TAU_S = 8;
initW = 1;
initType = Bernoulli;
selfLoopStrength = 0;
selfLoopRatio = 1;
LearningRate = 0.001;
]


[
LAYER = RESERVOIR;
NAME  = reservoir;
NUM_NEURONS = 250;
INPUT = hidden_1;
VTH = 10;
T_REFRAC = 2;
TAU_M = 128;
TAU_S = 8;
initW = 1;
Train_Reservoir = true;
#weightConnect = 32;#     # number of neurons connects to each input neuron #
initType = Bernoulli;
laterialType = RESERVOIR;  # the laterical connections type: RESERVOIR or LOCAL_INHIBITION # 
reservoirDim = 5 x 5 x 10;
LearningRate = 0.001;
]


[
LAYER = SPIKING;
NUM_CLASSES = 11;
NAME  = output;
NUM_NEURONS = 11;
INPUT = reservoir;
VTH = 5;
T_REFRAC = 2;
TAU_M = 128;
TAU_S = 8;
initW = 1;
initType = Bernoulli;
laterialType = LOCAL_INHIBITION;
localInbStrength = 1;
DESIRED_LEVEL = 35;
UNDESIRED_LEVEL = 5;
MARGIN = 5;
LearningRate = 0.001;
]


